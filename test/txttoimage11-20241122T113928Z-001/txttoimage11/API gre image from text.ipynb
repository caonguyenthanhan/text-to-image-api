{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"zZPichyAMm6v"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"jLXlZqf-IrW8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a8aa674e-f7da-469d-e937-ab075a4c1851"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/87.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.5/953.5 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.3/111.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.3/887.3 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117 -q\n","!pip install yolov5 -q\n","!pip install datasets -q\n","!pip install --upgrade diffusers transformers accelerate datasets -q\n","!pip install accelerate transformers diffusers datasets safetensors -q\n","!pip install --upgrade diffusers -q\n","!pip install ultralytics -q\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJBWSKRCLSEo"},"outputs":[],"source":["!pip show diffusers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6B4WSOOLlgK"},"outputs":[],"source":["# Đường dẫn đến tập dữ liệu\n","dataset_path = \"/content/drive/MyDrive/txttoimage11/dataset\""]},{"cell_type":"markdown","source":["    txttoimage11/\n","    ├──API tạo ảnh từ văn bản.ipynb # File code huấn luyện mô hình\n","    └── dataset/ # Thư mục chứa tập dữ liệu\n","          ├── naruto_1.jpg\n","          ├── naruto_1.txt\n","          ├──  naruto_2.jpg\n","          ├──  naruto_2.txt\n","          └── …"],"metadata":{"id":"vMpQfXrTIlyO"}},{"cell_type":"markdown","metadata":{"id":"UeCGLsUu2WDJ"},"source":["    \"\"\"\n","    Phân tích hình ảnh trong thư mục, dự đoán nhãn bằng mô hình,\n","    và lưu nhãn vào file văn bản tương ứng.\n","    \n","    Args:\n","        dataset_path (str): Đường dẫn đến thư mục chứa ảnh.\n","        model (YOLO): Mô hình YOLO được huấn luyện để phân tích ảnh.\n","    \"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"qB6KBLUBJMOw"},"outputs":[],"source":["import os\n","from PIL import Image\n","\n","def analyze_images(dataset_path, model):\n","    \"\"\"\n","    Phân tích hình ảnh trong thư mục, dự đoán nhãn bằng mô hình,\n","    và lưu nhãn vào file văn bản tương ứng.\n","    \"\"\"\n","    for filename in os.listdir(dataset_path):\n","        # Kiểm tra phần mở rộng của file\n","        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n","            image_path = os.path.join(dataset_path, filename)\n","            label_path = os.path.splitext(image_path)[0] + \".txt\"\n","\n","            # Kiểm tra xem file nhãn đã tồn tại\n","            if not os.path.exists(label_path):\n","                try:\n","                    # Tải và phân tích ảnh\n","                    image = Image.open(image_path)\n","                    results = model(image)\n","\n","                    # Trích xuất nhãn từ kết quả\n","                    labels = []\n","                    for *xyxy, conf, cls in results.xyxy[0]:  # Kết quả từ YOLO hoặc mô hình tương tự\n","                        label = model.names[int(cls)]  # Lấy tên nhãn từ ID lớp\n","                        labels.append(label)\n","\n","                    # Lưu nhãn vào file\n","                    with open(label_path, \"w\") as f:\n","                        f.write(\", \".join(labels))\n","                    print(f\"Lưu nhãn: {label_path}\")\n","                except Exception as e:\n","                    print(f\"Lỗi xử lý {filename}: {e}\")\n","            else:\n","                print(f\"File nhãn đã tồn tại: {label_path}\")\n","\n","# Ví dụ gọi hàm (cần thay 'dataset_path' và 'model' bằng dữ liệu của bạn)\n","# analyze_images(\"path/to/your/dataset\", your_model_instance)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xx3sF1Tnl9hL"},"outputs":[],"source":["from ultralytics import YOLO\n","\n","# Tải mô hình YOLOv5\n","model = YOLO(\"yolov5s.pt\")  # Thay bằng mô hình YOLO khác nếu cần\n","\n","# Gọi hàm phân tích ảnh\n","analyze_images(dataset_path, model)\n"]},{"cell_type":"markdown","source":["### Tiền xử lý ảnh: chuyển đổi ảnh PIL sang tensor và chuẩn hóa"],"metadata":{"id":"sJV8_26BC1cn"}},{"cell_type":"code","source":["def preprocess(image):\n","    \"\"\"\n","    Tiền xử lý ảnh: chuyển đổi ảnh PIL sang tensor và chuẩn hóa.\n","    \"\"\"\n","    preprocess = transforms.Compose([\n","        transforms.Resize((512, 512)),  # Thay đổi kích thước ảnh\n","        transforms.ToTensor(),         # Chuyển ảnh PIL sang tensor\n","    ])\n","    image = preprocess(image)\n","\n","    # Thêm một kênh vào tensor ảnh\n","    image = torch.cat([image, torch.ones_like(image[:1])], dim=0)\n","\n","    return image"],"metadata":{"id":"1iJiSZmIMlts"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GHO8LcIImq0a"},"outputs":[],"source":["# def preprocess(image):\n","#     \"\"\"\n","#     Tiền xử lý ảnh: chuyển đổi ảnh PIL sang tensor và chuẩn hóa.\n","#     \"\"\"\n","#     preprocess = transforms.Compose([\n","#         transforms.Resize((512, 512)),  # Thay đổi kích thước ảnh\n","#         transforms.ToTensor(),         # Chuyển ảnh PIL sang tensor\n","#         transforms.Normalize([0.5], [0.5])  # Chuẩn hóa dữ liệu (-1 đến 1)\n","#     ])\n","#     return preprocess(image)\n"]},{"cell_type":"markdown","source":["# Thiết lập Dataset và DataLoader"],"metadata":{"id":"5ku1uitKiydF"}},{"cell_type":"code","source":["import os\n","import json\n","from PIL import Image\n","from torchvision import transforms\n","from datasets import load_dataset\n","from torch.utils.data import DataLoader\n","import torch\n","from tqdm.auto import tqdm\n","from diffusers import StableDiffusionPipeline, DDPMScheduler\n","from torch.optim import AdamW\n","from accelerate import Accelerator\n","from flask import Flask, request, jsonify\n","import base64\n","from io import BytesIO"],"metadata":{"id":"80nN_wojDNaH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","import os\n","import json\n","from PIL import Image\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","from tqdm.auto import tqdm\n","from diffusers import StableDiffusionPipeline, DDPMScheduler\n","from torch.optim import AdamW\n","from accelerate import Accelerator\n","from flask import Flask, request, jsonify\n","import base64\n","from io import BytesIO\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, dataset_path):\n","        self.dataset_path = dataset_path\n","        self.image_files = [\n","            os.path.join(dataset_path, filename)\n","            for filename in os.listdir(dataset_path)\n","            if filename.lower().endswith(('.jpg', '.jpeg', '.png'))\n","        ]\n","\n","    def __len__(self):\n","        return len(self.image_files)\n","\n","    def __getitem__(self, idx):\n","        image_path = self.image_files[idx]  # Gán giá trị cho image_path\n","        image = Image.open(image_path).convert(\"RGB\")\n","        image = preprocess(image)  # Di chuyển dòng này ra ngoài khối try...except\n","\n","        label_path = os.path.splitext(image_path)[0] + \".txt\"\n","        try:\n","            with open(label_path, \"r\") as f:\n","                label = f.read().strip().split(\", \")\n","        except FileNotFoundError:\n","            print(f\"Không tìm thấy tệp nhãn: {label_path}\")\n","            label = []\n","\n","        # Padding danh sách nhãn\n","        max_length = 10  # Giả sử độ dài tối đa của danh sách nhãn là 10\n","        label = label[:max_length]  # Cắt ngắn nếu danh sách dài hơn max_length\n","        label += [\"<PAD>\"] * (max_length - len(label))  # Thêm padding\n","\n","        return {\"pixel_values\": image, \"labels\": label}\n","\n","# Tạo DataLoader\n","train_dataset = CustomDataset(dataset_path)\n","train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n"],"metadata":{"id":"n2ijybFCKrJ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def preprocess_function(examples):\n","#     images = [preprocess(image.convert(\"RGB\")) for image in examples[\"image\"]]\n","#     examples[\"pixel_values\"] = images\n","\n","#     # Trích xuất nhãn từ các tệp txt\n","#     labels = []\n","#     for i, image in enumerate(examples[\"image\"]):\n","#         filename = examples[\"image_file_path\"][i]\n","#         label_path = os.path.splitext(filename)[0] + \".txt\"\n","#         try:\n","#             with open(label_path, \"r\") as f:\n","#                 # Đọc nội dung từ tệp txt và tách thành danh sách các nhãn\n","#                 label = f.read().strip().split(\", \")\n","#             labels.append(label)\n","#         except FileNotFoundError:\n","#             print(f\"Không tìm thấy tệp nhãn: {label_path}\")\n","#             labels.append([])  # Hoặc xử lý lỗi theo cách khác\n","\n","#     examples[\"labels\"] = labels\n","\n","#     return examples\n","\n","# # Tải dataset bằng load_dataset\n","# dataset = load_dataset(\"imagefolder\", data_dir=dataset_path)\n","\n","# # Tạo danh sách files cho tập huấn luyện\n","# files = [os.path.join(dataset_path, filename) for filename in os.listdir(dataset_path) if filename.lower().endswith(('.jpg', '.jpeg', '.png'))]\n","\n","# # Thêm cột \"image_file_path\" cho tập huấn luyện\n","# def add_filepath(example, idx):\n","#     example['image_file_path'] = files[idx]  # Sử dụng danh sách files đã tạo\n","#     return example\n","\n","# dataset['train'] = dataset['train'].map(add_filepath, with_indices=True)\n","\n","# # Tiền xử lý dữ liệu TRƯỚC KHI tạo DataLoader\n","# dataset['train'] = dataset['train'].map(preprocess_function, batched=True, num_proc=4)\n","\n","# # Tạo DataLoader\n","# train_dataloader = DataLoader(dataset[\"train\"], batch_size=4, shuffle=True)\n"],"metadata":{"id":"olJbuzHzDJCy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Tải mô hình Stable Diffusion\n","pipe = StableDiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\")\n","\n","# Sử dụng DPMSolverMultistepScheduler\n","pipe.scheduler = DDPMScheduler.from_config(pipe.scheduler.config)\n","\n","# Chuyển model sang CPU\n","pipe.to(\"cpu\")  # Thay đổi dòng này\n","\n","# Optimizer\n","optimizer = AdamW(pipe.unet.parameters(), lr=5e-6)\n","\n","# Số epochs\n","num_epochs = 10"],"metadata":{"id":"1Oeom_8mLlhV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import CLIPTokenizer\n","# Khởi tạo tokenizer\n","tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n"],"metadata":{"id":"_-ERSbkhMNN_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn.utils.rnn as rnn_utils"],"metadata":{"id":"rLQT1pwbMb37"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gradient accumulation steps\n","gradient_accumulation_steps = 2\n","\n","# Vòng lặp huấn luyện\n","for epoch in range(num_epochs):\n","    progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n","    for step, batch in progress_bar:\n","\n","        # Di chuyển dữ liệu sang CPU\n","        pixel_values = batch[\"pixel_values\"].to(\"cpu\")  # Thay đổi dòng này\n","\n","        # Chuyển đổi batch[\"labels\"] thành tensor sử dụng tokenizer\n","        labels = [torch.tensor(tokenizer.encode(l, add_special_tokens=False)) for l in batch[\"labels\"]]\n","        labels = rnn_utils.pad_sequence(labels, batch_first=True, padding_value=tokenizer.pad_token_id).to(\"cpu\")  # Thay đổi dòng này\n","\n","        # Tạo noise ngẫu nhiên\n","        noise = torch.randn(pixel_values.shape).to(\"cpu\")  # Thay đổi dòng này\n","\n","        # Tạo timestep ngẫu nhiên\n","        timesteps = torch.randint(0, pipe.scheduler.config.num_train_timesteps, (pixel_values.shape[0],)).long().to(\"cpu\")  # Thay đổi dòng này\n","\n","        # Thêm noise vào ảnh gốc\n","        noisy_images = pipe.scheduler.add_noise(pixel_values, noise, timesteps)\n","\n","        # Dự đoán noise\n","        encoder_hidden_states = pipe.text_encoder(labels)[\"last_hidden_state\"]\n","        noise_pred = pipe.unet(noisy_images, timesteps, encoder_hidden_states=encoder_hidden_states).sample\n","\n","        # Tính loss\n","        loss = torch.nn.functional.mse_loss(noise_pred, noise)\n","\n","        # Backpropagation\n","        loss.backward()  # Thay đổi dòng này\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        # Hiển thị loss trên progress bar\n","        progress_bar.set_postfix({\"loss\": loss.item()})\n"],"metadata":{"id":"ifNI1dQpDXF6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Lưu mô hình"],"metadata":{"id":"huVpz_pqS394"}},{"cell_type":"code","source":["# Lưu mô hình\n","# pipe.save_pretrained(\"/content/drive/MyDrive/stable_diffusion_trained\")\n","\n","# Lưu mô hình sau khi huấn luyện\n","model.save_pretrained(\"/content/drive/MyDrive/txttoimage11\")\n"],"metadata":{"id":"x7ZZ2XplS2rD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E1C5Mtsg1GYM"},"source":["chuyển đổi ảnh thành định dạng base64 trước khi trả về."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"accKcbAq1C1n"},"outputs":[],"source":["import base64\n","from io import BytesIO\n","\n","def image_to_base64(image):\n","    buffered = BytesIO()\n","    image.save(buffered, format=\"PNG\")\n","    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n","    return img_str\n","\n","@app.route('/generate', methods=['POST'])\n","def generate():\n","    description = request.form['description']\n","    prompt = f\"{description}, no background\"\n","    image = pipe(prompt).images[0]\n","    image_base64 = image_to_base64(image)\n","    return jsonify({'image': image_base64})\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qNbYaLIzJT0w"},"outputs":[],"source":["from flask import Flask, request, jsonify\n","from diffusers import StableDiffusionPipeline\n","\n","app = Flask(__name__)\n","\n","# Tải mô hình Stable Diffusion đã huấn luyện\n","pipe = StableDiffusionPipeline.from_pretrained(\"path/to/save/model\")\n","pipe = pipe.to(\"cuda\")\n","\n","@app.route('/generate', methods=['POST'])\n","def generate():\n","    description = request.form['description']\n","    # Xử lý mô tả và tạo prompt (ví dụ: thêm \"no background\")\n","    prompt = f\"{description}, no background\"\n","    image = pipe(prompt).images[0]\n","    # Chuyển đổi image sang base64 hoặc lưu vào file\n","    # ...\n","    return jsonify({'image': image_base64})  # Trả về ảnh\n","\n","if __name__ == '__main__':\n","    app.run()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyMiDsv9INJr5dGCEZJBnS1O"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}