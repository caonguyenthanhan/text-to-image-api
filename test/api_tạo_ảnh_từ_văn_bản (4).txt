# -*- coding: utf-8 -*-
"""API tạo ảnh từ văn bản.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1peQzjWWjerE4n2nwbB7Ngyq9fVvgcogI
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117 -q
!pip install yolov5 -q
!pip install datasets -q
!pip install --upgrade diffusers transformers accelerate datasets -q
!pip install accelerate transformers diffusers datasets safetensors -q
!pip install --upgrade diffusers -q
!pip install ultralytics -q

!pip show diffusers

# Đường dẫn đến tập dữ liệu
dataset_path = "/content/drive/MyDrive/txttoimage11/dataset"

"""    '''
    Phân tích hình ảnh trong thư mục, dự đoán nhãn bằng mô hình,
    và lưu nhãn vào file văn bản tương ứng.
    
    Args:
        dataset_path (str): Đường dẫn đến thư mục chứa ảnh.
        model (YOLO): Mô hình YOLO được huấn luyện để phân tích ảnh.
    '''
"""

import os
from PIL import Image

def analyze_images(dataset_path, model):
    """
    Phân tích hình ảnh trong thư mục, dự đoán nhãn bằng mô hình,
    và lưu nhãn vào file văn bản tương ứng.
    """
    for filename in os.listdir(dataset_path):
        # Kiểm tra phần mở rộng của file
        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
            image_path = os.path.join(dataset_path, filename)
            label_path = os.path.splitext(image_path)[0] + ".txt"

            # Kiểm tra xem file nhãn đã tồn tại
            if not os.path.exists(label_path):
                try:
                    # Tải và phân tích ảnh
                    image = Image.open(image_path)
                    results = model(image)

                    # Trích xuất nhãn từ kết quả
                    labels = []
                    for *xyxy, conf, cls in results.xyxy[0]:  # Kết quả từ YOLO hoặc mô hình tương tự
                        label = model.names[int(cls)]  # Lấy tên nhãn từ ID lớp
                        labels.append(label)

                    # Lưu nhãn vào file
                    with open(label_path, "w") as f:
                        f.write(", ".join(labels))
                    print(f"Lưu nhãn: {label_path}")
                except Exception as e:
                    print(f"Lỗi xử lý {filename}: {e}")
            else:
                print(f"File nhãn đã tồn tại: {label_path}")

# Ví dụ gọi hàm (cần thay 'dataset_path' và 'model' bằng dữ liệu của bạn)
# analyze_images("path/to/your/dataset", your_model_instance)

from ultralytics import YOLO

# Tải mô hình YOLOv5
model = YOLO("yolov5s.pt")  # Thay bằng mô hình YOLO khác nếu cần

# Gọi hàm phân tích ảnh
analyze_images(dataset_path, model)

from torchvision import transforms

def preprocess(image):
    """
    Tiền xử lý ảnh: chuyển đổi ảnh PIL sang tensor và chuẩn hóa.
    """
    preprocess = transforms.Compose([
        transforms.Resize((512, 512)),  # Thay đổi kích thước ảnh
        transforms.ToTensor(),         # Chuyển ảnh PIL sang tensor
        transforms.Normalize([0.5], [0.5])  # Chuẩn hóa dữ liệu (-1 đến 1)
    ])
    return preprocess(image)

"""# chỉ CPU

# Thiết lập Dataset và DataLoader
"""

from datasets import load_dataset
from torch.utils.data import DataLoader
import torch
from tqdm.auto import tqdm
import os

# Tải dataset
dataset = load_dataset("imagefolder", data_dir=dataset_path )

# Tiền xử lý: Thêm trường "labels" vào dataset từ tệp nhãn YOLO
def preprocess_function(example):
    # Lấy đường dẫn đến tệp nhãn
    image_path = example["image"]
    label_path = os.path.splitext(image_path)[0] + ".txt"

    # Kiểm tra xem tệp nhãn có tồn tại không
    if os.path.exists(label_path):
        with open(label_path, "r") as f:
            labels = []
            for line in f.readlines():
                # Đọc từng dòng trong tệp nhãn và chuyển thành list
                class_id, x_center, y_center, width, height = map(float, line.strip().split())
                labels.append({
                    "class_id": int(class_id),
                    "x_center": x_center,
                    "y_center": y_center,
                    "width": width,
                    "height": height
                })
        example["labels"] = labels  # Lưu nhãn vào trường "labels"
    else:
        example["labels"] = []  # Nếu không có nhãn, gán danh sách rỗng

    return example

# Tiền xử lý dữ liệu
dataset["train"] = dataset["train"].map(preprocess_function)

# Tạo DataLoader
train_dataloader = DataLoader(dataset["train"], batch_size=4, shuffle=True)

"""# Thiết lập Mô hình và Scheduler"""

from diffusers import UNet2DModel, DDPMScheduler
from torch.optim import AdamW

# Tạo mô hình UNet
model = UNet2DModel(
    sample_size=64,  # Kích thước ảnh (đảm bảo phù hợp với dữ liệu của bạn)
    in_channels=3,   # Số kênh đầu vào (3 nếu RGB)
    out_channels=3,  # Số kênh đầu ra
    layers_per_block=2,
    block_out_channels=(64, 128, 256),
)

# Tạo Scheduler
scheduler = DDPMScheduler(num_train_timesteps=1000)

# Optimizer
optimizer = AdamW(model.parameters(), lr=5e-6)

# Di chuyển model sang GPU nếu có
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Số epochs
num_epochs = 10

# Vòng lặp huấn luyện
for epoch in range(num_epochs):
    model.train()
    progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))
    for step, batch in progress_bar:
        # Di chuyển dữ liệu sang thiết bị (GPU hoặc CPU)
        pixel_values = batch["pixel_values"].to(device)

        # Tạo noise ngẫu nhiên
        noise = torch.randn(pixel_values.shape).to(device)

        # Tạo timestep ngẫu nhiên
        timesteps = torch.randint(0, scheduler.config.num_train_timesteps, (pixel_values.shape[0],)).long().to(device)

        # Thêm noise vào ảnh gốc
        noisy_images = scheduler.add_noise(pixel_values, noise, timesteps)

        # Dự đoán noise
        noise_pred = model(noisy_images, timesteps).sample

        # Tính loss
        loss = torch.nn.functional.mse_loss(noise_pred, noise)

        # Backpropagation
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # Hiển thị loss trên progress bar
        progress_bar.set_postfix({"loss": loss.item()})

"""# Lưu mô hình"""

# Lưu mô hình
# pipe.save_pretrained("/content/drive/MyDrive/stable_diffusion_trained")

# Lưu mô hình sau khi huấn luyện
model.save_pretrained("/content/drive/MyDrive/txttoimage11")

"""chuyển đổi ảnh thành định dạng base64 trước khi trả về."""

import base64
from io import BytesIO

def image_to_base64(image):
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
    return img_str

@app.route('/generate', methods=['POST'])
def generate():
    description = request.form['description']
    prompt = f"{description}, no background"
    image = pipe(prompt).images[0]
    image_base64 = image_to_base64(image)
    return jsonify({'image': image_base64})

from flask import Flask, request, jsonify
from diffusers import StableDiffusionPipeline

app = Flask(__name__)

# Tải mô hình Stable Diffusion đã huấn luyện
pipe = StableDiffusionPipeline.from_pretrained("path/to/save/model")
pipe = pipe.to("cuda")

@app.route('/generate', methods=['POST'])
def generate():
    description = request.form['description']
    # Xử lý mô tả và tạo prompt (ví dụ: thêm "no background")
    prompt = f"{description}, no background"
    image = pipe(prompt).images[0]
    # Chuyển đổi image sang base64 hoặc lưu vào file
    # ...
    return jsonify({'image': image_base64})  # Trả về ảnh

if __name__ == '__main__':
    app.run()